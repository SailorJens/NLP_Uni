{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ddc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If Find My is offline or not working - Apple Support\n",
      "If Find My is offline or not working\n",
      "Learn what to do if you don't see your device listed, you see an alert that says your device is offline, or you see an unexpected device in Find My.\n",
      "I don't see my device in Find My\n",
      "I see my device in Find My, but it's offline\n",
      "I see a device that I donâ€™t own or use anymore\n",
      "I use a device associated with a business or educational institution\n",
      "I don't see my device in Find My\n",
      "Make sure that you\n",
      "set up Find My\n",
      "on your device. You have to set up Find My before you can see your device in the Find My app or on\n",
      "iCloud.com/find\n",
      ".\n",
      "If your device is lost\n",
      "If your device is missing,\n",
      "learn how to mark your device as lost and protect your information\n",
      ".\n",
      "If you have your device with you\n",
      "Check that you signed in to iCloud on your device using your Apple Account: Tap Settings. If you see \"Sign in to your [device],\" tap it and enter your Apple Account email address or phone number and password.\n",
      "Make sure that you s\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the website you want to fetch \n",
    "url = \"https://support.apple.com/sitemap\"\n",
    "\n",
    "# Step 1: Download the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "\n",
    "# Step 2: Parse HTML and extract text\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Remove scripts, styles, and other non-visible elements\n",
    "for element in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\"]):\n",
    "    element.decompose()\n",
    "\n",
    "# Get only the visible text\n",
    "text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "# Now `text` contains the webpage text\n",
    "print(text[:1000])  # print first 1000 characters as a preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aac4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "\n",
    "def extract_text_from_html(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # Find the main content div\n",
    "    content_div = soup.find(\"div\", id=\"sections\")\n",
    "    if not content_div:\n",
    "        return \"\"\n",
    "    \n",
    "     # Remove all tables entirely\n",
    "    for table in content_div.find_all(\"table\"):\n",
    "        table.decompose()\n",
    "\n",
    "    # Elements that should start a new line\n",
    "    block_tags = {\"h1\", \"h2\", \"h3\", \"p\"}\n",
    "\n",
    "    # Elements that are inline (flattened)\n",
    "    inline_tags = {\"a\", \"b\", \"i\", \"span\", \"li\", \"ul\"}\n",
    "\n",
    "    # Recursive function to extract text\n",
    "    def recurse(element):\n",
    "        texts = []\n",
    "        for child in element.children:\n",
    "            if child.name in block_tags:\n",
    "                # Start a new line for block elements\n",
    "                texts.append(recurse(child).strip())\n",
    "                texts.append(\"\\n\")\n",
    "            elif child.name in inline_tags:\n",
    "                # Inline: flatten the tag, keep its children\n",
    "                texts.append(recurse(child))\n",
    "            elif child.string:\n",
    "                # Text node\n",
    "                texts.append(child.string)\n",
    "            elif hasattr(child, \"children\"):\n",
    "                # Other tags: recurse\n",
    "                texts.append(recurse(child))\n",
    "        return \"\".join(texts)\n",
    "\n",
    "    extracted_text = recurse(content_div)\n",
    "    \n",
    "    # Clean up extra whitespace and multiple newlines\n",
    "    lines = [line.strip() for line in extracted_text.split(\"\\n\") if line.strip()]\n",
    "    # relace non-breaking spaces\n",
    "    lines = [line.replace(\"\\xa0\", \" \") for line in lines]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "start_id = 102701\n",
    "end_id = 102799\n",
    "text = ''\n",
    "\n",
    "# for each id in the range, download and extract text\n",
    "for article_id in range(start_id, end_id + 1):\n",
    "    # URL of the website you want to fetch\n",
    "    url = f\"https://support.apple.com/en-us/{article_id}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        html_content = response.text\n",
    "        text += extract_text_from_html(html_content)\n",
    "        text += \"\\n\" \n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "\n",
    "with open(f\"data/text2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b90282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://support.apple.com/en-us/102666\"\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching {url}: {e}\")\n",
    "\n",
    "with open(f\"data/102666.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
