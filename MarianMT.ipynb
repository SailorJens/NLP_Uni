{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713cdaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "import torch\n",
    "\n",
    "# Your retrained or standard MarianMT model\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-de\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Use GPU/Metal if available, otherwise CPU\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# Example long document (replace with your text)\n",
    "document = \"\"\"\n",
    "Your very long document text goes here...\n",
    "It could be several thousand words, spanning multiple paragraphs.\n",
    "\"\"\"\n",
    "\n",
    "# Split document into sentences or paragraphs (simplest: by newline or periods)\n",
    "chunks = [chunk.strip() for chunk in document.split(\"\\n\") if chunk.strip()]\n",
    "# Optional: you can further split very long paragraphs into smaller chunks\n",
    "\n",
    "translated_chunks = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    # Tokenize chunk\n",
    "    inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    \n",
    "    # Generate translation\n",
    "    translated_tokens = model.generate(**inputs, max_length=1024)  # adjust max_length if needed\n",
    "    \n",
    "    # Decode\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    translated_chunks.append(translated_text)\n",
    "\n",
    "# Combine translated chunks\n",
    "full_translation = \"\\n\".join(translated_chunks)\n",
    "\n",
    "print(full_translation)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
