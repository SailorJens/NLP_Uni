{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcxBE3mBfMkI"
      },
      "source": [
        "# TODO — Applied NLP Mini-Project: Intelligent FAQ Assistant\n",
        "\n",
        "In this final exercise, you will combine the skills learned in the previous tasks:\n",
        "\n",
        "- From **Exercise 1**: using pre-trained Transformers for text classification.  \n",
        "- From **Exercise 2**: building a semantic search engine using embeddings.\n",
        "\n",
        "Your goal is to create a **simple Intelligent FAQ Assistant**:\n",
        "1. Use a Transformer model to **classify** a user query into a topic (e.g., “product”, “payment”, “technical”).  \n",
        "2. Use **semantic search** to find the most relevant FAQ entry within that topic.  \n",
        "3. Return the best-matched answer to the user.\n",
        "\n",
        "This brings together everything learned in Weeks 3 & 4 — modern Transformer-based NLP applications.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHplrwTUfUFY"
      },
      "source": [
        "# 1. Environment Setup\n",
        "### Install the Hugging Face and evaluation libraries we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSx8ZH8tfE4D"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install -q sentence-transformers datasets scikit-learn\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import torch, numpy as np, pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAar_AWXfigP"
      },
      "source": [
        "### 2) Create a Small FAQ Dataset\n",
        "\n",
        "For simplicity, we’ll simulate a small FAQ base with three topics:\n",
        "- Product\n",
        "- Payment\n",
        "- Technical\n",
        "\n",
        "Each entry has a *question* and an *answer*.\n",
        "\n",
        "You can replace this dataset with your own domain data later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8y0xFSjfhUm"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"topic\": [\"product\",\"product\",\"product\",\n",
        "              \"payment\",\"payment\",\"payment\",\n",
        "              \"technical\",\"technical\",\"technical\"],\n",
        "    \"question\": [\n",
        "        \"What features does the new phone have?\",\n",
        "        \"Is the laptop waterproof?\",\n",
        "        \"Do you sell smart watches?\",\n",
        "        \"How can I get a refund?\",\n",
        "        \"Is there a discount for students?\",\n",
        "        \"Can I change my payment method?\",\n",
        "        \"How do I reset my password?\",\n",
        "        \"Why is my app crashing?\",\n",
        "        \"Does the software work on Linux?\"\n",
        "    ],\n",
        "    \"answer\": [\n",
        "        \"The new phone includes a dual camera and 5G support.\",\n",
        "        \"The laptop is not waterproof; keep it away from water.\",\n",
        "        \"Yes, we offer several smart watch models online.\",\n",
        "        \"You can request a refund from your order history page.\",\n",
        "        \"Yes, students can apply a 10% discount at checkout.\",\n",
        "        \"You can update payment methods from your account settings.\",\n",
        "        \"Go to Settings → Security → Reset Password.\",\n",
        "        \"Try reinstalling the app and clearing cached data.\",\n",
        "        \"Yes, our software is compatible with Linux systems.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "faq_df = pd.DataFrame(data)\n",
        "faq_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz3LCjybfryx"
      },
      "source": [
        "### 3) Train a Simple Topic Classifier\n",
        "\n",
        "We will use sentence embeddings from a pre-trained model (`all-MiniLM-L6-v2`)\n",
        "and train a **lightweight logistic regression classifier** to predict the FAQ topic.\n",
        "\n",
        "This keeps training fast while still relying on Transformer-based representations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoCp5ZpBfsM_"
      },
      "outputs": [],
      "source": [
        "# Load model for sentence embeddings\n",
        "# Hint: Use SentenceTransformer with the pre-trained model \"all-MiniLM-L6-v2\"\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Encode questions into dense vectors\n",
        "# Hint: Convert all FAQ questions into numerical embeddings using model.encode()\n",
        "# It could be argued that retrieval may be better when embedding the Answers, or even Quaetions + Answers.\n",
        "# (cf. Wen-Ting Tseng, Tien-Hong Lo, Yung-Chang Hsu, Berlin Chen (2020). Effective FAQ Retrieval and Question Matching With Unsupervised Knowledge Injection. arXiv)\n",
        "# I need numpy arrays as output because only those work with e.g. train_test_split.\n",
        "# As I don't have massive amounts of data, I can run this on CPU.\n",
        "X = model.encode(faq_df[\"question\"].tolist(), convert_to_numpy=True)\n",
        "\n",
        "\n",
        "# Hint: Convert text topic labels (e.g., 'product', 'payment', 'technical') into numeric codes\n",
        "# I don't encode the topics, because they are the target labels. Technically I could leave them as strings\n",
        "# as many classifiers handle them internally. But apparently it is better to keep them numeric\n",
        "# (cf. Julian, D. & Raschka, S., Hearty, J (2016):\n",
        "# Python: Deeper Insights into Machine Learning.\n",
        "# Packt Publishing. Chapter 4, \"Building Good Training Sets – Data Preprocessing\").\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(faq_df[\"topic\"])\n",
        "\n",
        "\n",
        "# Split for validation\n",
        "# Hint: Use train_test_split to divide data into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train simple classifier\n",
        "# Hint: Create a LogisticRegression model and fit it using the training embeddings and labels. try max iteration 500.\n",
        "# LogisticRegression is a simple linear classifier that works with high-dimensional data.\n",
        "# I found several references that that is the case for sparce data (e.g. https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html),\n",
        "# but none that talks about dense vectors. However, it seems to work well here.\n",
        "clf = LogisticRegression(max_iter=500)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "# Hint: Predict topics on test data and print a classification report to see accuracy and F1-score\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=faq_df[\"topic\"].unique()))\n",
        "\n",
        "# The results are very good. It seems the queries are positioned in the embedding vector space in a way that\n",
        "# hyperplanes can be defined that groups the queries matching the topic labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esbJStfpXaI1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x8t5rZMf-c-"
      },
      "source": [
        "### 4) Build Semantic Search for Each Topic\n",
        "\n",
        "Now we create a dictionary of embeddings per topic so that once the\n",
        "classifier predicts a topic, we can perform **semantic similarity search**\n",
        "within that topic only.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2qGmWLpHgN41"
      },
      "outputs": [],
      "source": [
        "# Hint: Group the FAQ DataFrame by topic to create a separate subset for each category\n",
        "topic_groups = {topic: subdf for topic, subdf in faq_df.groupby(\"topic\")}\n",
        "# We now have a dictionary with the topics as keys, and a smaller df with the faqs for the topic.\n",
        "\n",
        "# Hint: Create an empty dictionary to store embeddings for each topic\n",
        "topic_embeddings = {}\n",
        "\n",
        "# Hint: Loop through each topic group and encode its questions into embeddings\n",
        "for topic, subdf in topic_groups.items():\n",
        "    # Use the same model to create embeddings for all questions under this topic\n",
        "    topic_embeddings[topic] = model.encode(subdf[\"question\"].tolist(), convert_to_numpy=True)\n",
        "\n",
        "# so now topic_embeddings is a dictionary with topics as keys, and numpy arrays as value that contain the embeddings for\n",
        "# the questions of the FAQs for the respective topic.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "988kElyNgYlv"
      },
      "source": [
        "### 5) Query the Assistant\n",
        "\n",
        "When a user enters a question:\n",
        "1. Classify it to find the most likely topic.  \n",
        "2. Perform semantic similarity search within that topic’s FAQs.  \n",
        "3. Return the most relevant answer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1ykJLQ-hgd4L"
      },
      "outputs": [],
      "source": [
        "def faq_assistant(query):\n",
        "    # Step 1: Encode query\n",
        "    # Hint: Convert the user’s input text into an embedding using the same model\n",
        "    # As the query is a string, I need to put in a list, as the classifier expects an array\n",
        "    q_emb = model.encode([query], convert_to_numpy=True)\n",
        "\n",
        "    # Step 2: Predict topic\n",
        "    # Hint: Use the trained classifier to predict which topic the query belongs to\n",
        "    topic_id = clf.predict(q_emb)[0]\n",
        "\n",
        "    # Hint: Convert the numeric topic ID back to the original topic name\n",
        "    # As I used LabelEncoder to transform the topic into an id, I need to reverse the operation\n",
        "    # Again, as this predicting an individual value, I need to wrap topic_id into a list,\n",
        "    # because inverse_transform expects that.\n",
        "    topic_name = le.inverse_transform([topic_id])[0]\n",
        "    print(f\"\\n\\nPredicted Topic: {topic_name.title()}\\n\")\n",
        "    print(f\"Asked question: {query}\")\n",
        "\n",
        "    # Step 3: Semantic search within topic\n",
        "    # Hint: Select all FAQs related to the predicted topic\n",
        "    topic_df = topic_groups[topic_name]\n",
        "\n",
        "    # Hint: Retrieve precomputed embeddings for that topic’s questions\n",
        "    topic_vecs = topic_embeddings[topic_name]\n",
        "\n",
        "    # Hint: Convert the query embedding to a tensor and move it to the same device as topic embeddings\n",
        "    # As I used NumPy rather than Tensors for my embeddings, I don't need the device method.\n",
        "    # This will always just run on CPU.\n",
        "    q_tensor = torch.tensor(q_emb, dtype=torch.float32)\n",
        "\n",
        "    # Hint: Compute cosine similarity between the query and all topic question embeddings\n",
        "    cos_scores = util.cos_sim(q_tensor, topic_vecs)[0]\n",
        "\n",
        "    # Hint: Find the index of the most similar question\n",
        "    best_idx = torch.argmax(cos_scores).item()\n",
        "\n",
        "    # Hint: Print the matched FAQ question and its corresponding answer\n",
        "    print(f\"Matched Question: {topic_df.iloc[best_idx]['question']}\")\n",
        "    print(f\"Answer: {topic_df.iloc[best_idx]['answer']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEiIU_fAggNR"
      },
      "source": [
        "### 6) Test the System\n",
        "\n",
        "Try different queries and see if the assistant finds the right FAQ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKHaFBsCgsN8",
        "outputId": "e20cba02-78e0-4b31-d2c1-a3a71329f54b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Predicted Topic: Payment\n",
            "\n",
            "Asked question: How can I pay using PayPal?\n",
            "Matched Question: Can I change my payment method?\n",
            "Answer: You can update payment methods from your account settings.\n",
            "\n",
            "\n",
            "Predicted Topic: Product\n",
            "\n",
            "Asked question: My phone is broken, what warranty do I have?\n",
            "Matched Question: What features does the new phone have?\n",
            "Answer: The new phone includes a dual camera and 5G support.\n",
            "\n",
            "\n",
            "Predicted Topic: Technical\n",
            "\n",
            "Asked question: App keeps freezing when I open it.\n",
            "Matched Question: Why is my app crashing?\n",
            "Answer: Try reinstalling the app and clearing cached data.\n",
            "\n",
            "\n",
            "Predicted Topic: Product\n",
            "\n",
            "Asked question: When was the latest iPad model released?\n",
            "Matched Question: What features does the new phone have?\n",
            "Answer: The new phone includes a dual camera and 5G support.\n",
            "\n",
            "\n",
            "Predicted Topic: Payment\n",
            "\n",
            "Asked question: Will I get a refund?\n",
            "Matched Question: How can I get a refund?\n",
            "Answer: You can request a refund from your order history page.\n",
            "\n",
            "\n",
            "Predicted Topic: Product\n",
            "\n",
            "Asked question: How do I find out about the new iOS features?\n",
            "Matched Question: What features does the new phone have?\n",
            "Answer: The new phone includes a dual camera and 5G support.\n"
          ]
        }
      ],
      "source": [
        "# To summarise what's happening:\n",
        "# We are doing a 2 step retrieval:\n",
        "# First we identify a topic with a simple linear classifier that was trained with the question embeddings.\n",
        "# (It would be interesting to understand how including the answers in the training would change the accuracy of the predictions.)\n",
        "# Then we do a search within the topic to find the actual FAQ entry that comes closest to the question.\n",
        "# This is an alternative approach to what we did in the exercise with doing a similarity search directly (with FAISS) and\n",
        "# then use cross-encoder reanking.\n",
        "# I couldn't find concrete references why one would prefer the one over the other.\n",
        "# However, predicting the topic first mean that less similarity calculations need to be done.\n",
        "# This should improve the performance. There is a risk though when the accuracy of the linear model is low.\n",
        "# In case of a wrong prediction the similarity search wouldn't have the chance to find the correct question.\n",
        "# Therefore this approach only makes sense when the topics are well separated.\n",
        "# Because on the other hand we learned that FAISS is also extremely powerful, so if the splitting into topics\n",
        "# is not done well, the FAISS + Cross-Encodeing Reranking may be preferred.\n",
        "\n",
        "\n",
        "faq_assistant(\"How can I pay using PayPal?\")\n",
        "faq_assistant(\"My phone is broken, what warranty do I have?\")\n",
        "faq_assistant(\"App keeps freezing when I open it.\")\n",
        "\n",
        "faq_assistant(\"When was the latest iPad model released?\")\n",
        "faq_assistant(\"Will I get a refund?\")\n",
        "faq_assistant(\"How do I find out about the new iOS features?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOPwapoXg0MG"
      },
      "source": [
        "### ✅ Expected Outcome\n",
        "Your system should:\n",
        "- Correctly identify the FAQ topic.  \n",
        "- Retrieve and display the most relevant answer.  \n",
        "\n",
        "This simple pipeline demonstrates how Transformer-based representations enable modern NLP applications that *understand meaning* rather than relying on keywords.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Report**\n",
        "\n",
        "\n",
        "We are doing a 2 step retrieval:\n",
        "\n",
        "First we identify a topic with a simple linear classifier that was trained with the question embeddings. (It would be interesting to understand how including the answers in the training would change the accuracy of the predictions.)\n",
        "\n",
        "Then we do a search within the topic to find the actual FAQ entry that comes closest to the question.\n",
        "\n",
        "This is an alternative approach to what we did in the exercise with doing a similarity search directly (with FAISS) and then use cross-encoder reanking.\n",
        "\n",
        "I couldn't find concrete references why one would prefer the one over the other.\n",
        "\n",
        "However, predicting the topic first means that less similarity calculations need to be done. This should improve the performance. \n",
        "\n",
        "There is a risk though when the accuracy of the linear model is low. In case of a wrong prediction the similarity search wouldn't have the chance to find the correct question Therefore this approach only makes sense when the topics are well separated.\n",
        "\n",
        "In the exercise we learned that FAISS is also extremely powerful. If the splitting into topics is not done well, the FAISS + Cross-Encoding Reranking may be preferred.\n",
        "\n",
        "I am quite intrigued though how good linear classifiers seem to be with topic detection. I am wondering if that also works for content categories, like technical vs. medical vs. marketing vs. legal; or for different stylistic nuances (formal, informal.). Another question I have if how to proceed if \"a document\" is a whole article rather than just a question. I will try that out. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwR3WHajmTU_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
